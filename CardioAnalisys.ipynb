{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CardioAnalisys.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-W0_rwFi-5",
        "outputId": "c672a4b1-b4b3-4834-d2a1-3857ac9c5418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Habilitando o acesso ao Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhw14eEx6rlv"
      },
      "source": [
        "#Neste projeto, iremos analisar o dataset Cardiovascular Disease dataset, extraído do Kaggle: https://www.kaggle.com/sulianova/cardiovascular-disease-dataset\n",
        "\n",
        "###Inicialmente, é realizado um tratamento dos dados, separando, por exemplo, dados categóricos em one-hot vectors. Posteriormente, é feita uma breve análise de correlação entre as features e os labels.\n",
        "\n",
        "###A seguir, features consideradas menos relevantes são retiradas e features que influenciam indiretamente são combinadas, gerando novas relações. Um exemplo de feature nova criada é o IMC - Índice de massa corporal, que utiliza uma relação entre altura e peso, mostrando-se mais adequado do que apenas essas duas features sozinhas.\n",
        "\n",
        "###Por fim, utilizando pytorch, é implementada uma MLP para realizar a tarefa de classificação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOklBfrCJkWl"
      },
      "source": [
        "Descrição dos dados:\n",
        "\n",
        "*   Coluna 1: Idade em dias (inteiro)\n",
        "*   Coluna 2: Altura em cm (inteiro)\n",
        "*   Coluna 3: Peso em kg (float)\n",
        "*   Coluna 4: Gênero (dado categórico)\n",
        "*   Coluna 5: Pressão sanguínea sistólica (inteiro)\n",
        "*   Coluna 6: Pressão sanguínea diastólica (inteiro)\n",
        "*   Coluna 7: Colesterol (1 - normal; 2 - acima do normal; 3 muito acima do normal)\n",
        "*   Coluna 8: Glicose (1 - normal; 2 - acima do normal; 3 muito acima do normal)\n",
        "*   Coluna 9: Consumo de cigarro (1 - Sim ; 0 - Não)\n",
        "*   Coluna 10: Consumo de álcool (1 - Sim ; 0 - Não)\n",
        "*   Coluna 11: Realiza atividade física (1 - Sim ; 0 - Não)\n",
        "*   Coluna 12: Presença ou ausência de doença cardiovascular (1 - Sim ; 0 - Não)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW8amtBhF3H_",
        "outputId": "f219833e-d8cf-43b8-f794-f81d454409d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Importando o dataset\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/cardio_train.csv\", sep=';')\n",
        "dataset"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18393</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20228</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18857</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>17623</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>82.0</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>17474</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>56.0</td>\n",
              "      <td>100</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>99993</td>\n",
              "      <td>19240</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>76.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>99995</td>\n",
              "      <td>22601</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>126.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>99996</td>\n",
              "      <td>19066</td>\n",
              "      <td>2</td>\n",
              "      <td>183</td>\n",
              "      <td>105.0</td>\n",
              "      <td>180</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>99998</td>\n",
              "      <td>22431</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>72.0</td>\n",
              "      <td>135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>99999</td>\n",
              "      <td>20540</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id    age  gender  height  weight  ...  gluc  smoke  alco  active  cardio\n",
              "0          0  18393       2     168    62.0  ...     1      0     0       1       0\n",
              "1          1  20228       1     156    85.0  ...     1      0     0       1       1\n",
              "2          2  18857       1     165    64.0  ...     1      0     0       0       1\n",
              "3          3  17623       2     169    82.0  ...     1      0     0       1       1\n",
              "4          4  17474       1     156    56.0  ...     1      0     0       0       0\n",
              "...      ...    ...     ...     ...     ...  ...   ...    ...   ...     ...     ...\n",
              "69995  99993  19240       2     168    76.0  ...     1      1     0       1       0\n",
              "69996  99995  22601       1     158   126.0  ...     2      0     0       1       1\n",
              "69997  99996  19066       2     183   105.0  ...     1      0     1       0       1\n",
              "69998  99998  22431       1     163    72.0  ...     2      0     0       0       1\n",
              "69999  99999  20540       1     170    72.0  ...     1      0     0       1       0\n",
              "\n",
              "[70000 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AmxE1hBGc6z"
      },
      "source": [
        "#A primeira coluna é indiferente para análise. Por isso, iremos eliminá-la\n",
        "dataset = dataset.drop(columns=[\"id\"])"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfjlKV4WuF5A",
        "outputId": "b14583b2-18ac-4930-a047-dceb03b8e087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Vamos checar o balanceamento dos True Negativos(Não tem doença cardíaca) e True Positivos(tem doença cardíaca do dataset)\n",
        "positivo = 0\n",
        "negativo = 0\n",
        "for i in dataset['cardio']:\n",
        "  if(dataset['cardio'][i] == 1):\n",
        "    positivo += 1\n",
        "  elif(dataset['cardio'][i] == 0):\n",
        "    negativo += 1\n",
        "  else:\n",
        "    print(\"ERRO NO LABEL DO DATASET\")\n",
        "\n",
        "print(\"POSITIVO: \", positivo)\n",
        "print(\"NEGATIVO: \", negativo)\n",
        "\n",
        "#Como os dados estão balanceados, não é necessário realizar um balenceamento"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "POSITIVO:  34979\n",
            "NEGATIVO:  35021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civcrtuS40BE"
      },
      "source": [
        "Para uma análise extra e treinar a manipulação dos dados, vamos medir o índice de massa corporal de cada um dos indivíduos. Não se trata de uma medida ideal pois provavelmente um indicador da porcentagem de gordura corporal traria melhores resultados, porém é uma análise válida que pode ser feita. O cálculo do IMC é dado por:\n",
        "\n",
        "$$\\frac{Peso}{Altura^2}$$\n",
        "\n",
        "Onde a altura é calculada em metros e o peso em kg.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXO0RNQy4x1_",
        "outputId": "434314e9-c596-4ab0-e869-13babc78b498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "peso = dataset['weight']\n",
        "altura = dataset['height']/100\n",
        "\n",
        "IMC = peso/(altura*altura)\n",
        "\n",
        "dataset['imc'] = IMC\n",
        "dataset"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "      <th>imc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18393</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21.967120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20228</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.927679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18857</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.507805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17623</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>82.0</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>28.710479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17474</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>56.0</td>\n",
              "      <td>100</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.011177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>19240</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>76.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.927438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>22601</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>126.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.472681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>19066</td>\n",
              "      <td>2</td>\n",
              "      <td>183</td>\n",
              "      <td>105.0</td>\n",
              "      <td>180</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.353579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>22431</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>72.0</td>\n",
              "      <td>135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.099251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>20540</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.913495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         age  gender  height  weight  ...  alco  active  cardio        imc\n",
              "0      18393       2     168    62.0  ...     0       1       0  21.967120\n",
              "1      20228       1     156    85.0  ...     0       1       1  34.927679\n",
              "2      18857       1     165    64.0  ...     0       0       1  23.507805\n",
              "3      17623       2     169    82.0  ...     0       1       1  28.710479\n",
              "4      17474       1     156    56.0  ...     0       0       0  23.011177\n",
              "...      ...     ...     ...     ...  ...   ...     ...     ...        ...\n",
              "69995  19240       2     168    76.0  ...     0       1       0  26.927438\n",
              "69996  22601       1     158   126.0  ...     0       1       1  50.472681\n",
              "69997  19066       2     183   105.0  ...     1       0       1  31.353579\n",
              "69998  22431       1     163    72.0  ...     0       0       1  27.099251\n",
              "69999  20540       1     170    72.0  ...     0       1       0  24.913495\n",
              "\n",
              "[70000 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRthvlqYL7b1"
      },
      "source": [
        "#Agora, iremos analisar a correlação entre as features e o label.\n",
        "#Começando com dados quantitativos, iremos criar um heatmap para analisar a correlação entre uma feature e a presença de doença cardiovascular.\n",
        "categorical_data = dataset[['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']]\n",
        "numerical_data = dataset[['age', 'height', 'weight', 'ap_hi', 'ap_lo','imc', 'cardio']]"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luVuyNuFppUP"
      },
      "source": [
        "Agora vamos normalizar os dados numéricos. Para isso, utilizaremos o min-max feature scaling, que reescala os dados para o range [0,1] através da equação:\n",
        "    $$ \\frac{X_{norm}}{X_{max} -X_{min}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ8PgTjKtUeS",
        "outputId": "52752d05-c804-4558-9cf7-f5d5b82430a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "def min_max_scaling(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply min-max scaling\n",
        "    for column in df_norm.columns:\n",
        "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
        "        \n",
        "    return df_norm\n",
        "\n",
        "numerical_data = min_max_scaling(numerical_data)\n",
        "numerical_data"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>imc</th>\n",
              "      <th>cardio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.588076</td>\n",
              "      <td>0.579487</td>\n",
              "      <td>0.273684</td>\n",
              "      <td>0.016079</td>\n",
              "      <td>0.013550</td>\n",
              "      <td>0.062655</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.517949</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>0.017934</td>\n",
              "      <td>0.014453</td>\n",
              "      <td>0.106560</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.624003</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.284211</td>\n",
              "      <td>0.017316</td>\n",
              "      <td>0.012647</td>\n",
              "      <td>0.067874</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.528455</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.378947</td>\n",
              "      <td>0.018553</td>\n",
              "      <td>0.015357</td>\n",
              "      <td>0.085498</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.516918</td>\n",
              "      <td>0.517949</td>\n",
              "      <td>0.242105</td>\n",
              "      <td>0.015461</td>\n",
              "      <td>0.011743</td>\n",
              "      <td>0.066192</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>0.653659</td>\n",
              "      <td>0.579487</td>\n",
              "      <td>0.347368</td>\n",
              "      <td>0.016698</td>\n",
              "      <td>0.013550</td>\n",
              "      <td>0.079458</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>0.913899</td>\n",
              "      <td>0.528205</td>\n",
              "      <td>0.610526</td>\n",
              "      <td>0.017934</td>\n",
              "      <td>0.014453</td>\n",
              "      <td>0.159220</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0.640186</td>\n",
              "      <td>0.656410</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.014453</td>\n",
              "      <td>0.094452</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>0.900736</td>\n",
              "      <td>0.553846</td>\n",
              "      <td>0.326316</td>\n",
              "      <td>0.017625</td>\n",
              "      <td>0.013550</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>0.754317</td>\n",
              "      <td>0.589744</td>\n",
              "      <td>0.326316</td>\n",
              "      <td>0.016698</td>\n",
              "      <td>0.013550</td>\n",
              "      <td>0.072636</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            age    height    weight     ap_hi     ap_lo       imc  cardio\n",
              "0      0.588076  0.579487  0.273684  0.016079  0.013550  0.062655     0.0\n",
              "1      0.730159  0.517949  0.394737  0.017934  0.014453  0.106560     1.0\n",
              "2      0.624003  0.564103  0.284211  0.017316  0.012647  0.067874     1.0\n",
              "3      0.528455  0.584615  0.378947  0.018553  0.015357  0.085498     1.0\n",
              "4      0.516918  0.517949  0.242105  0.015461  0.011743  0.066192     0.0\n",
              "...         ...       ...       ...       ...       ...       ...     ...\n",
              "69995  0.653659  0.579487  0.347368  0.016698  0.013550  0.079458     0.0\n",
              "69996  0.913899  0.528205  0.610526  0.017934  0.014453  0.159220     1.0\n",
              "69997  0.640186  0.656410  0.500000  0.020408  0.014453  0.094452     1.0\n",
              "69998  0.900736  0.553846  0.326316  0.017625  0.013550  0.080040     1.0\n",
              "69999  0.754317  0.589744  0.326316  0.016698  0.013550  0.072636     0.0\n",
              "\n",
              "[70000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQCcUSRMm66",
        "outputId": "ac136d6f-870f-4080-b4ac-40b7791d9fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Transformando dados categóricos em one-hot vectors\n",
        "categorical_data = pd.concat([categorical_data, pd.get_dummies(categorical_data['gender'], prefix='gender')], axis = 1)\n",
        "categorical_data = pd.concat([categorical_data, pd.get_dummies(categorical_data['cholesterol'], prefix='cholesterol')], axis = 1)\n",
        "categorical_data = pd.concat([categorical_data, pd.get_dummies(categorical_data['gluc'], prefix='gluc')], axis = 1)\n",
        "categorical_data = pd.concat([categorical_data, pd.get_dummies(categorical_data['cardio'], prefix='cardio')], axis = 1)\n",
        "\n",
        "#Retirando os que não são one-hot \n",
        "categorical_data = categorical_data.drop(columns=['gender', 'cholesterol', 'gluc'])\n",
        "\n",
        "categorical_data\n"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "      <th>gender_1</th>\n",
              "      <th>gender_2</th>\n",
              "      <th>cholesterol_1</th>\n",
              "      <th>cholesterol_2</th>\n",
              "      <th>cholesterol_3</th>\n",
              "      <th>gluc_1</th>\n",
              "      <th>gluc_2</th>\n",
              "      <th>gluc_3</th>\n",
              "      <th>cardio_0</th>\n",
              "      <th>cardio_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       smoke  alco  active  cardio  ...  gluc_2  gluc_3  cardio_0  cardio_1\n",
              "0          0     0       1       0  ...       0       0         1         0\n",
              "1          0     0       1       1  ...       0       0         0         1\n",
              "2          0     0       0       1  ...       0       0         0         1\n",
              "3          0     0       1       1  ...       0       0         0         1\n",
              "4          0     0       0       0  ...       0       0         1         0\n",
              "...      ...   ...     ...     ...  ...     ...     ...       ...       ...\n",
              "69995      1     0       1       0  ...       0       0         1         0\n",
              "69996      0     0       1       1  ...       1       0         0         1\n",
              "69997      0     1       0       1  ...       0       0         0         1\n",
              "69998      0     0       0       1  ...       1       0         0         1\n",
              "69999      0     0       1       0  ...       0       0         1         0\n",
              "\n",
              "[70000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B46aEht3aEpl",
        "outputId": "7a67ec4f-c98b-42f1-b268-6d123a91a28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "#Vamos criar um BarPlot para analisar a correlação das features com o label\n",
        "#Para a correlação, utilizaremos o método de pearson\n",
        "aux_cat_data = categorical_data.drop(columns=['cardio_0', 'cardio_1'])\n",
        "cor_pearson = aux_cat_data.corr(method='pearson')\n",
        "\n",
        "#Dropando o cardio, pois ele tem uma relação de 1 para 1 com o cárdio\n",
        "cor_pearson = cor_pearson.drop('cardio')\n",
        "\n",
        "#Plotando um gráfico de barras com a correlação\n",
        "cor_pearson['cardio'].plot.bar(subplots=True, color='g')\n"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f73afa0b0b8>],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFBCAYAAAB6hqiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxfdX3v8deb1aUqBGLAwAhi7BWviDqArUVbFsEqi5bNKzQqNvVe6eZSQaoo7kvrbSvXGpVFKyIIalQqhqhoVSRhKRgtTUCRpEEwhEWQJfC+f5wz8GOYSWbyO+d3kt/3/Xw8fo+cdd7f78DMZ872PbJNRESUa7OuGxAREd1KIYiIKFwKQURE4VIIIiIKl0IQEVG4FIKIiMKlEES0TNIvJB1QT79d0qe7blNEry26bkBESWy/v+s2RIyXI4KIhkjKH1axSUohiKhJ2lnSBZJukbRa0scl7Sbp2/X8ryV9XtI2Pfv8QtLbJF0N3CVpC0nHSbqh3ufkcRnvkvSvPfOHSloq6TZJ35X0zAF2OQJIIYgAQNLmwNeBG4BdgNnAOYCADwBPAZ4J7Ay8a9zurwJeBmwDPAP4BHBcvc92wE6TZD4D+ALw18BM4ELga5K2aqxjEVOQQhBR2ZvqF/dbbd9l+x7b/257ue2Ftu+1fQvwD8CLx+37T7ZvtP1b4Ajg67a/Z/te4B3Ag5NkHg18o/769wMfBR4L/H4bHYyYTM5pRlR2Bm6wvbZ3oaRZwD8C+wJPoPrjac24fW/smX5K77ztuyStniTzKVRHIGPbPijpRqqjkYiByRFBROVGYGSCC77vBww82/YTgWOpThf16h3CdxVVUQFA0uOoTg9N5L+Bp/Zsq3rflRvSgYgNlUIQUbmM6pf4ByU9XtJjJL2Q6ijgN8DtkmYDb13P1/kS8HJJf1Cf6z+VyX/OzgVeJml/SVsCbwbuBX7YQH8ipiyFIAKw/QBwCPB04JfACqpz+O8GngfcDnwDuGA9X2cp8EbgbKrCsqb+WhNtey3VEcY/A7+u8w+xfV//PYqYOuXFNBERZcsRQURE4VIIIiIKl0IQEVG4FIKIiMKlEEREFG6TfLJ4++239y677NJ1MyIiNimXX375r23PHL98kywEu+yyC0uWLOm6GRERmxRJN0y0vJFTQ5IOlnStpOWSTpxg/Zsk/VTS1ZIWSep9rH6upGX1Z24T7YmIiKnruxDUw/eeBrwU2B14laTdx212JTBqew+qR/A/XO87AzgF2Idq9MdTJG3bb5siImLqmjgi2BtYbvv6+tH4c4DDejew/R3bd9ezl/Lw+OwHAQtt32p7DbAQOLiBNkVExBQ1UQhm88hheFew7mF0jwf+bQP3jYiIhg30YrGkY4FRHv1ij6nsOw+YBzAyMtJwyyIiytXEEcFKesZfpzrt86jx1CUdAJwMHFq/uWnK+wLYnm971PbozJmPuvspIiI2UBOFYDEwR9Ku9fjrxwALejeQ9Fzgk1RF4OaeVRcBL5G0bX2R+CX1soiIGJC+Tw3ZXivpBKpf4JsDp9teKulUYIntBcBHgN8BzqtewsQvbR9q+1ZJ76EqJgCn2r613zZFRMTUbZLvIxgdHXUeKIsYDL17/Js5p8enbHq/Y4aVpMttj45fnrGGIiIKl0IQEVG4FIKIiMKlEEREFC6FICKicCkEERGFSyGIiChcCkFEROFSCCIiCpdCEBFRuBSCiIjCpRBERBQuhSAionApBBERhUshiIgoXApBREThGikEkg6WdK2k5ZJOnGD9iyRdIWmtpCPGrXtA0lX1Z8H4fSMiol19v6pS0ubAacCBwApgsaQFtn/as9kvgdcAb5ngS/zW9p79tiMiIjZM34UA2BtYbvt6AEnnAIcBDxUC27+o1z3YQF5ERDSoiVNDs4Ebe+ZX1Mum6jGSlki6VNLhDbQnIiKmoYkjgn491fZKSU8Dvi3pGtvXjd9I0jxgHsDIyMig2xgRMbSaOCJYCezcM79TvWxKbK+s/70e+C7w3Em2m2971PbozJkzN7y1ERHxCE0UgsXAHEm7StoKOAaY0t0/kraVtHU9vT3wQnquLURERPv6LgS21wInABcBPwPOtb1U0qmSDgWQtJekFcCRwCclLa13fyawRNJ/AN8BPjjubqOIiGhZI9cIbF8IXDhu2Tt7phdTnTIav98PgWc30YaIiNgwebI4IqJwKQQREYVLIYiIKFwKQURE4VIIIiIKl0IQEVG4FIKIiMKlEEREFC6FICKicCkEERGFSyGIiChcCkFEROFSCCIiCpdCEBFRuBSCiIjCpRBERBSukUIg6WBJ10paLunECda/SNIVktZKOmLcurmSltWfuU20JyIipq7vQiBpc+A04KXA7sCrJO0+brNfAq8Bzh637wzgFGAfYG/gFEnb9tumiIiYuiaOCPYGltu+3vZ9wDnAYb0b2P6F7auBB8ftexCw0PatttcAC4GDG2hTRERMUROFYDZwY8/8inpZ2/tGREQDNpmLxZLmSVoiacktt9zSdXMiIoZGE4VgJbBzz/xO9bJG97U93/ao7dGZM2duUEMjIuLRmigEi4E5knaVtBVwDLBgivteBLxE0rb1ReKX1MsiImJA+i4EttcCJ1D9Av8ZcK7tpZJOlXQogKS9JK0AjgQ+KWlpve+twHuoisli4NR6WUREDMgWTXwR2xcCF45b9s6e6cVUp30m2vd04PQm2hEREdO3yVwsjoiIdqQQREQULoUgIqJwKQQREYVr5GJxRLRP79YG7+tT3GBLYtjkiCAionApBBERhUshiIgoXApBREThcrE4ImIj0sVNATkiiIgoXApBREThUggiIgqXQhARUbgUgoiIwqUQREQUrpFCIOlgSddKWi7pxAnWby3pi/X6H0vapV6+i6TfSrqq/vxLE+2JiIip6/s5AkmbA6cBBwIrgMWSFtj+ac9mxwNrbD9d0jHAh4Cj63XX2d6z33ZERMSGaeKBsr2B5bavB5B0DnAY0FsIDgPeVU9/Cfi4pA1/aiIiokX9PNQFm95or02cGpoN3Ngzv6JeNuE29cvubwe2q9ftKulKSZdI2reB9kRExDR0PcTEKmDE9mpJzwe+IulZtu8Yv6GkecA8gJGRkQE3MyJieDVxRLAS2Llnfqd62YTbSNoCeBKw2va9tlcD2L4cuA54xkQhtufbHrU9OnPmzAaaHRER0EwhWAzMkbSrpK2AY4AF47ZZAMytp48Avm3bkmbWF5uR9DRgDnB9A22KiIgp6vvUkO21kk4ALgI2B063vVTSqcAS2wuAzwCfk7QcuJWqWAC8CDhV0v3Ag8AbbN/ab5siImLqGrlGYPtC4MJxy97ZM30PcOQE+50PnN9EGyIiYsPkyeKIiMKlEEREFC6FICKicCkEERGFSyGIiChcCkFEROFSCCIiCpdCEBFRuBSCiIjCpRBERBQuhSAionApBBERhUshiIgoXApBREThUggiIgrX9TuLIzaI3q0N3tenuMGWRGz6GjkikHSwpGslLZd04gTrt5b0xXr9jyXt0rPupHr5tZIOaqI9ERExdX0Xgvqdw6cBLwV2B14lafdxmx0PrLH9dOBjwIfqfXenem3ls4CDgf839g7jiIgYjCaOCPYGltu+3vZ9wDnAYeO2OQw4q57+ErC/JNXLz7F9r+2fA8vrrxcREQPSxDWC2cCNPfMrgH0m26Z+2f3twHb18kvH7Tt7ohBJ84B5ACMjI5M2pp9zx9Df+eOuzluX2Ocuz/OX1ud8rweri+xN5q4h2/Ntj9oenTlzZtfNiYgYGk0UgpXAzj3zO9XLJtxG0hbAk4DVU9w3IiJa1EQhWAzMkbSrpK2oLv4uGLfNAmBuPX0E8G3brpcfU99VtCswB7isgTZFRMQU9X2NoD7nfwJwEbA5cLrtpZJOBZbYXgB8BvicpOXArVTFgnq7c4GfAmuBN9p+oN82daXE+9NL7HPEsGnkgTLbFwIXjlv2zp7pe4AjJ9n3fcD7mmhHRERM3yZzsTgiItqRQhARUbihG2so56wjIqYnRwQREYVLIYiIKFwKQURE4VIIIiIKl0IQEVG4FIKIiMKlEEREFC6FICKicCkEERGFG7oni0uUp6kjoh85IoiIKFwKQURE4foqBJJmSFooaVn977aTbDe33maZpLk9y78r6VpJV9WfJ/fTnoiImL5+jwhOBBbZngMsqucfQdIM4BRgH2Bv4JRxBePVtvesPzf32Z6IiJimfgvBYcBZ9fRZwOETbHMQsND2rbbXAAuBg/vMjYiIhvRbCGbZXlVP3wTMmmCb2cCNPfMr6mVjzqhPC71DkvpsT0RETNN6bx+VdDGwwwSrTu6dsW1J072P8dW2V0p6AnA+cBzw2UnaMQ+YBzAyMjLNmIiImMx6C4HtAyZbJ+lXkna0vUrSjsBE5/hXAn/YM78T8N36a6+s/71T0tlU1xAmLAS25wPzAUZHR3PjfEREQ/o9NbQAGLsLaC7w1Qm2uQh4iaRt64vELwEukrSFpO0BJG0JvBz4SZ/tiYiIaeq3EHwQOFDSMuCAeh5Jo5I+DWD7VuA9wOL6c2q9bGuqgnA1cBXVkcOn+mxPRERMU19DTNheDew/wfIlwOt75k8HTh+3zV3A8/vJj4iI/uXJ4oiIwqUQREQULoUgIqJwKQQREYVLIYiIKFwKQURE4VIIIiIKl0IQEVG4FIKIiMKlEEREFC6FICKicCkEERGFSyGIiChcCkFEROFSCCIiCpdCEBFRuL5eTCNpBvBFYBfgF8BRttdMsN03gRcA/2775T3LdwXOAbYDLgeOs31fP22KiOHhU/J68kHo94jgRGCR7TnAonp+Ih8Bjptg+YeAj9l+OrAGOL7P9kRExDT1WwgOA86qp88CDp9oI9uLgDt7l0kSsB/wpfXtHxER7em3EMyyvaqevgmYNY19twNus722nl8BzO6zPRERMU3rvUYg6WJghwlWndw7Y9uSWjuhJ2keMA9gZGSkrZiIiOKstxDYPmCydZJ+JWlH26sk7QjcPI3s1cA2kraojwp2Alauox3zgfkAo6OjuYIUEdGQfk8NLQDm1tNzga9OdUfbBr4DHLEh+0dERDP6LQQfBA6UtAw4oJ5H0qikT49tJOn7wHnA/pJWSDqoXvU24E2SllNdM/hMn+2JiIhp6us5Aturgf0nWL4EeH3P/L6T7H89sHc/bYiIiP7kyeKIiMKlEEREFC6FICKicCkEERGFSyGIiChcCkFEROFSCCIiCpdCEBFRuBSCiIjCpRBERBQuhSAionApBBERhUshiIgoXApBREThUggiIgqXQhARUbi+CoGkGZIWSlpW/7vtJNt9U9Jtkr4+bvmZkn4u6ar6s2c/7YmIiOnr94jgRGCR7TnAonp+Ih8Bjptk3Vtt71l/ruqzPRERMU39FoLDgLPq6bOAwyfayPYi4M4+syIiogX9FoJZtlfV0zcBszbga7xP0tWSPiZp6z7bExER07Tel9dLuhjYYYJVJ/fO2LYkTzP/JKoCshUwH3gbcOok7ZgHzAMYGRmZZkxERExmvYXA9gGTrZP0K0k72l4laUfg5umE9xxN3CvpDOAt69h2PlWxYHR0dLoFJyIiJtHvqaEFwNx6ei7w1ensXBcPJInq+sJP+mxPRERMU7+F4IPAgZKWAQfU80galfTpsY0kfR84D9hf0gpJB9WrPi/pGuAaYHvgvX22JyIipmm9p4bWxfZqYP8Jli8BXt8zv+8k++/XT35ERPQvTxZHRBQuhSAionApBBERhUshiIgoXApBREThUggiIgqXQhARUbgUgoiIwqUQREQULoUgIqJwKQQREYVLIYiIKFwKQURE4VIIIiIKl0IQEVG4FIKIiML1VQgkzZC0UNKy+t9tJ9hmT0k/krRU0tWSju5Zt6ukH0taLumLkrbqpz0RETF9/R4RnAgssj0HWFTPj3c38Ke2nwUcDPxfSdvU6z4EfMz204E1wPF9ticiIqap30JwGHBWPX0W1QvoH8H2f9leVk//N3AzMLN+Yf1+wJfWtX9ERLSr30Iwy/aqevomYNa6Npa0N7AVcB2wHXCb7bX16hXA7D7bExER07Tel9dLuhjYYYJVJ/fO2LYkr+Pr7Ah8Dphr+8HqgGDqJM0D5gGMjIxMa9+IiJjceguB7QMmWyfpV5J2tL2q/kV/8yTbPRH4BnCy7UvrxauBbSRtUR8V7ASsXEc75gPzAUZHRyctOBERMT39nhpaAMytp+cCXx2/QX0n0JeBz9oeux6AbQPfAY5Y1/4REdEuVb+PN3BnaTvgXGAEuAE4yvatkkaBN9h+vaRjgTOApT27vsb2VZKeBpwDzACuBI61fe/6ckdHR71kyZINbndERIkkXW579FHL+ykEXUkhiIiYvskKQZ4sjogoXApBREThUggiIgqXQhARUbgUgoiIwqUQREQULoUgIqJwKQQREYXbJB8ok3QL1ZPMG2J74NcNNmdjz+0yO30uIzt93nRyn2p75viFm2Qh6IekJRM9WTesuV1mp89lZKfPm35uTg1FRBQuhSAionAlFoL5heV2mZ0+l5GdPm/iucVdI4iIiEcq8YggIiJ6pBBERBQuhSAionBFFAJJsyR9RtK/1fO7Szp+ALk7SfqypFsk3SzpfEk7tZ1bZ3fS56hIOnAAGU+UtNsEy/doOXcHSTvU0zMlvVLSs9rMXE973jmAjIMkHS9pl3HLX9dipiQdJenIenp/Sf8k6f9IavR3dxGFADgTuAh4Sj3/X8BfDyD3DGABsGOd/bV62SCcSTd9fhRJ17T89XeWdI6k70t6u6Qte9Z9pc3sdfhMm19c0lHAfwLnS1oqaa+e1We2mPvnwI+ASyX9b+DrwMuACzr8Q+P1bX5xSe8HTgaeDSyS9Bc9q09oMfo04CjgOOBzwBuAxcCLgI81GbRFk19sI7a97XMlnQRge62kBwaQO9N27y/+MyUN6pfxQPss6ZWTrQJ2aCu3djpwPnApcDxwiaRDbK8GntpWqKQFk60Ctmsrt/Z24Pm2V0naG/icpJNsf7nOb8sJwLOAx1IN8/J02zdJ2hb4Di0VQEl3TLaqbkubDgGeW/8MvQs4W9LTbP8N7X6v97X97PoPm5uAHW3fJ+kLwBVNBpVSCO6StB1gAEkvAG4fQO5qSccCX6jnXwWsHkAuDL7PXwQ+P5Y3zmNazIWq4P5LPf0X9ff8e5IOnaQ9TdkXOBb4zbjlAvZuMRdgc9urAGxfJumPgK9L2pl2+3y/7buBuyVdZ/umug1rJLWZexuwl+1fjV8h6cYWcwG2sL0WwPZtkg4B5ks6D9iqxdyxzPslLbZ9Xz2/VtKDTQaVUgjeRHWKZjdJPwBmAkcMIPd1wD9THcYZ+CHw2gHkAryZwfb5auCjtn8yfoWkA1rMBdhS0mNs3wNg+18l3UR1auzxLeZeCtxt+5LxKyRd22IuwJ2SdrN9HUB9ZPCHwFeo/mJviyVtaft+qlNCAEh6DO2eav4s1dHdowoBcHaLuQDXSXrx2H9n2w8Ax0t6L/AnLebeJOl3bP/G9sFjC+vrM/c1GVTEA2WSdgVuBH6X6q+1a4E9bS/utGEtk7QFPX2uf3jbytoXuMH2LydYN2p7SYvZfwNcMf4XsqTnAh+23fqF20GT9BzgLtvLxy3fEjjK9udbyh0B/nvsL+Se5bOBZ9q+uI3cqZL0LNtLG/6ajwWw/dsJ1s22vbKt7Ena83jg8bZvbizX9tB/gMuB2T3zLwKuGUDuWcA2PfPbAqcPqM9XU51H3q3r7/+4dp1UWjbwow773El2h7lXdPi97iS7idxS7hp6A/CV+ra3P6Y6XfPHA8jdw/ZtYzO21wDPHUAuVBe41gLnSlos6S31X3NdO7LA7LavkWyM2V3ltnnxdmPN7ju3iELg6hTQXwLfAt4FHGC77QtMAJvVd1MAIGkGA7ouY/sG2x+2/XzgfwF7AD8fRPZ6lPiD2uX5166yS8vtMrvv3KG+WCzpazzym/Q4qjtnPiMJ24e23IS/B35U310gqou172s58yGSngocXX8eAP52UNnrUOIPasRGbagLAfDRLsNtf1bSEmC/etErbf90ENmSfgxsCZwHHGn7+kHkTkGJRwTp8+A0ejfNJpLdd+5QnxqyfcnYh+opzCfUn595glv+miJpxtiH6kGQs+vPTfWyQfhT28+z/YFBFQFJm9d38KzLecOWPQXHdZTbZXYruZJeIelJPfPbSDp8bN72C9rI7TJ7ELml3D56FPAR4LtUf6nsC7zV9pdayvs51WmIsb+Kxr7JAmz7aW3k1tnHurqP/k0Trbf9D21l1/mX2W77YaqNIlvSnTzydJN4+L+7bT9x2LK77HOdf5XtPcctu9J26zdhdJU9iNxhPzU05mSqpxLH7rudCVwMtFIIbO86Nl0fAcxhcHdRjD1A9YQJ1g2i6v9A0sepnjS+66Fgu9FH4jeGbNsTfY8HoqvsLvtcm+gsxqB+j3WV3XpuKUcE19h+ds/8ZsB/9C5rKff1wF8BOwFXAS8Afmh7/zZz6+wX2v7B+pa1kPudCRbb9n4TLB+m7OdQHWkCfM/21W1ndp3dRa6k06mGmzitXvRGYIbt1wxr9iBySykEH6G6fXJszJ+jqR4oa/UuGlWjbu4FXGp7T0n/A3i/7ckGaGsy+wrbz1vfsuifpL8C/gy4oF70CmC+7X8e1uwOcx8PvAMYG7ZkIfBe23dNvtemnT2I3CIKAYCkPwFeWM9+39UojW1nLra9l6SrgH1s3ytpqe3WxoKR9HvA71MNOd07VO0TgVfYfk5b2XX+LOD9wFNsv1TS7sDv2W51WOYusyVdXefcVc8/nurJ2lbfC9Bldpd9juaVco0A2+dLWkjdZ0kzbN/acuwKSdtQDQS2UNIaqqF727QV8DtU/ew9n3sHgxlo70yqdy6cXM//F9U5+9YLQYfZonpOY8wDDO72ya6yO8mtT/896q/XAZ56HHj2IHKLKASqXqbxbuAe4EEevtOhtbt3AGy/op58V/0f80nAN1vOvIRqPP4zbbdddCbS1bsfusw+A/ixpLGjzMMZTOHrMrur3Lf0TD+GavTPtZNsOyzZrecWUQiovpH/0/avu2pAm88tTOLTko4cG+uoHuriHNsHtZzb1bsfOsmubzy4lOrW5D+oF7/W9pVt5naZ3WWfbV8+btEPJF3Wdm6X2YPILaUQXAfc3XUjBmz78QPeSXryAHK7evdDJ9m2H5R0Wn1P9yBuke08u8s+j3sgczPg+VRH2kObPYjcUgrBScAP62EX7h1baPsvu2tS6x6UNOL6/QCqXrrd+p0Btq+Q9GIG9B6EjSR7UX0zwgUe/N0XXWV3lXs5Dz/AtpZqIMVBvSu5q+zWc4u4a6g+jPp34BqqawQA2D6rs0a1TNLBwHzgEh5+mnqe7YtaylvnLbG2L1jX+k01u86/k+pBvgeA3zKgp2y7zO6yz9G8UgrBQB5B39jUp4LmAVdSveD7ZtvfaynrjHryyVS3r367nv8jqofoXt5GbtfZMRgl/qExyNxSTg39m6R5wNd45Kmhtm8f7cwkTzX/iIdHQm2U7dfWud8Cdnf9YnVJO1Ld1tmaLrPrHAGvBna1/R5VL5Df0XbrFxK7yu4g95AJlj00xhEPP9g2TNkDyy3liKD3hSwPddgtDv7Wta6eapb0M9vP7JnfDFjau2zYsiV9guqU4362n1nfofUt23u1mdtldoe5b+bRAzreDlxu+6phzB5EbilHBG8Dvmn7DknvAJ4HvKfjNrXtHtv3SELS1rb/U9LvDiB3kaSLeORwHoN6oXlX2fvYfp6kK+GhO7S2GkBul9ld5T4fGKW6O0zAy6nez/0GSefZ/vAQZreeW0oh+Lv6QaM/oDo18lHgE8A+3TarVV081YztE+pzm2ODkc0fxHAeHWffL2lzHn5+YSY9NyUMaXZXuTsBz7P9mzr3FOAbwIuo7q5psxB0ld16bimFYOzp0pcBn7L9DUnv7bJBbeviqeae7Ato95ztxpb9T8CXgSdLeh/VswvvGPLsrnKfTM91PuB+YJbt30q6d5J9NvXs1nNLKQQrJX0SOBD4kKStGfK3s/Ua5FPN9V/kH6L6n1cM9lbKTrJtf17S5cD+debhtn/WZmbX2R32+fNUQ1t8tZ4/BDhb1aB3bb8Gtqvs1nNLuVj8OOBgqqGnl9V3kzzb9rc6btrQkbQcOGRQvwg3hmxJn7N93PqWDVN2x30e5eGRhH9ge0nbmV1nt51bRCGIwZH0A9svXP+Ww5Otce95qM+dX2N792HN7rLP0bxSTg3F4CyR9EWqi9S9z2wM4rz9QLNVjXL6duCxku4YWwzcR/VUd2u6yu6yz9GeHBFEo3qe8u1l268b1mxJH7B9UpsZG1t2l32O5qUQRPRJ0guBq2zfJelYqudU/tEDeB9EV9ld9jmaV8ydMzEYkp4haZGkn9Tze0j6uyHP/gRwt6qXub+Zatjzzw4gt8vsLvscDUshiKZ9imrY7/sBbF8NHDPk2WtdHVofBnzc9mk88jWhw5jdZZ+jYblYHE17nO3LqjHJHjKoVwl2lX1nfRH1OGDfeoyjLQeQ22V2l32OhuWIIJr2a0m78fDQA0cAq4Y8+2iqu5ReZ/smqiEBPjKA3C6zu+xzNCwXi6NRkp5GdRvh7wNrqN6m9OoBXTjtMvupwBzbF9cPMG5u+862c7vM7rLP0awUgmiUpDfVk4+lOuK8i8ENE9xJtqQ/o3oB0Azbu0maA/yL7f3byuw6u8s+R/NyaiiaNgq8AdgW2Ab4c6rhPT4l6W+HNPuNVI//3wFgexnVeEeD0FV2l32OhuVicTStxGGC77V939hFaklb0PMCpJZ1ld1ln6NhOSKIpk06ZO645cOUfYmksWEXDgTOo3ot6iB0ld1ln6NhOSKIppU4TPCJwPHANVSnoy4EPt1i3saQ3WWfo2G5WByNK3GY4IhNWQpBxAaSdA3rOC9ue49hy+6yz9GeFIKIDVTfRz+pNp9f6Cq7yz5He1IIIhogaRawVz17me2bhz27yz5Hs3LXUESfJB0FXAYcCRxFdcH6iGHO7rLP0bwcEUT0SdJ/AAeO/UUsaSZwse3nDGt2l32O5uWIIDJFMskAAAFSSURBVKJ/m407LbKawf1sdZXdZZ+jYXmOIKJ/35R0EfCFev5oqvvqhzm7yz5Hw3JqKKIBkv6Eh59f+L7tLw97dpd9jmalEEREFC7n9CL6JOmVkpZJul3SHZLulHTHMGd32edoXo4IIvokaTlwiO2flZLdZZ+jeTkiiOjfrzr8hdhVdpd9jobliCBiA0l6ZT35YmAH4Cv0DHdt+4Jhy+6yz9GeFIKIDSTpjHrSgMattu3XDVt2l32O9uQ5gogNZPu1AJLOAv7K9m31/LbA3w9jdpd9jvbkGkFE//YY+4UIYHsN8Nwhz+6yz9GwFIKI/m1W/0UMgKQZDO5ou6vsLvscDct/uIj+/T3wI0nn1fNHAu8b8uwu+xwNy8XiiAZI2h3Yr579tu2238/ceXaXfY5mpRBERBQu1wgiIgqXQhARUbgUgoiIwqUQREQULoUgIqJw/x8YYHZCwLfvjQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPf9nihOreXW"
      },
      "source": [
        "Como podemos notar pelo gráfico, algumas features possuem uma relação muito baixa com doenças cardíacas, como por exemplo fumar, alcool, genero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGN9V3_ovoBS",
        "outputId": "34cec82f-fb13-4641-928f-d7090fb26166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "#Agora, vamos analisar os dados numéricos\n",
        "#Para a correlação, utilizaremos o método de pearson\n",
        "cor_pearson = numerical_data.corr(method='pearson')\n",
        "\n",
        "#Dropando o cardio, pois ele tem uma relação de 1 para 1 com o cárdio\n",
        "cor_pearson = cor_pearson.drop('cardio')\n",
        "\n",
        "#Plotando um gráfico de barras com a correlação\n",
        "cor_pearson['cardio'].plot.bar(subplots=True, color='g', )"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f73ae857780>],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPG7SN2mwXfY"
      },
      "source": [
        "Removeremos da análise a altura, pois diretamente ela não tem alta correlação com o fato da pessoa ter doença cardíaca ou não.\n",
        "\n",
        "Além disso, note que o imc possui uma correlação menor do que o peso. Isso se dá pois, analisando apenas o peso, acabamos levando em consideração indivíduos que são mais pesados por terem um maior indice de massa corporal e também indivíduos que são mais pesados por serem mais altos. Dessa forma, utilizando o IMC, excluímos o segundo caso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6YboIWUAut0"
      },
      "source": [
        "###Agora vamos separar os dados de treino e teste, tão bem como as features e labels. Além disso, retiraremos as features que não serão utilizadas no treino.\n",
        "\n",
        "###Faremos duas análises. Uma considerando apenas o IMC e não o peso, e outra considerando apenas o peso e não o IMC.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg9P5Rq2A0Pl"
      },
      "source": [
        "#Dados para o treino considerando o Peso\n",
        "aux1 = numerical_data[[\"age\", \"weight\", \"ap_hi\", \"ap_lo\"]]\n",
        "aux2 = categorical_data[[\"cholesterol_1\", \"cholesterol_2\", \"cholesterol_3\", \"gluc_1\", \"gluc_2\", \"gluc_3\", \"cardio_0\", \"cardio_1\"]]\n",
        "aux3 = pd.concat([aux1, aux2], axis=1)\n",
        "\n",
        "train_weight_x, train_weight_y = aux3.iloc[0:60000, 0:10], aux3.iloc[0:60000, 10:12]\n",
        "\n",
        "test_weight_x, test_weight_y = aux3.iloc[60001: -1, 0:10], aux3.iloc[60001: -1, 10:12]\n",
        "\n",
        "#Dados para o treino considerando o IMC\n",
        "aux1 = numerical_data[[\"age\", \"imc\", \"ap_hi\", \"ap_lo\"]]\n",
        "aux2 = categorical_data[[\"cholesterol_1\", \"cholesterol_2\", \"cholesterol_3\", \"gluc_1\", \"gluc_2\", \"gluc_3\", \"cardio\"]]\n",
        "aux3 = pd.concat([aux1, aux2], axis=1)\n",
        "\n",
        "train_imc_x, train_imc_y = aux1.iloc[0:60000, 0:10], aux3.iloc[0:60000, 10:11]\n",
        "\n",
        "test_imc_x, test_imc_y = aux3.iloc[60001:70000, 0:10], aux3.iloc[60001:70000, 10:11]"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISx1TN6zNPRV"
      },
      "source": [
        "## **Agora vamos para o treino :)** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw9L3wKRNWVX"
      },
      "source": [
        "Primeiramente, vamos criar nosso modelo de análise. Para este problema, foi escolhida uma Multi-Layer Perceptron para realizar a classificação.\n",
        "\n",
        "A arquitetura usada pela rede foi:\n",
        "\n",
        "Learning Rate: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYZPV4FINzaY"
      },
      "source": [
        "Abaixo, é definido o modelo da nossa rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbbg5IEXN4w2",
        "outputId": "1264efb1-6b98-46b9-dd30-9ad253bca75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Definindo o modelo da rede\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Cardio_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Cardio_Model, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(10, 8)\n",
        "\n",
        "    self.fc2 = nn.Linear(8, 6)\n",
        "    self.fc3 = nn.Linear(6, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "\n",
        "    return F.sigmoid(self.fc3(x))\n",
        "\n",
        "#Testando a rede\n",
        "model = Cardio_Model()\n",
        "model"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cardio_Model(\n",
              "  (fc1): Linear(in_features=10, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=6, bias=True)\n",
              "  (fc3): Linear(in_features=6, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24eUytiaDxqY"
      },
      "source": [
        "##**Definindo Variáveis e Hiperparâmetros**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx29BeDKRqyp"
      },
      "source": [
        "#Definindo Variáveis e Hiperparâmetros\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 250\n",
        "LEARNING_RATE = 0.002\n",
        "print_results = 60000\n",
        "\n",
        "#Criando o modelo\n",
        "cardio_model = Cardio_Model()\n",
        "\n",
        "#Setando o optimizador e a loss function\n",
        "optimizer = torch.optim.Adam(params=cardio_model.parameters(), lr=LEARNING_RATE)\n",
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmF3kjDbULWd"
      },
      "source": [
        "Agora, vamos separar nossos dados em batches\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-9OPcfwfd1K"
      },
      "source": [
        "tensor_x = torch.tensor(train_weight_x.values, dtype=torch.float32)\n",
        "tensor_y = torch.tensor(train_weight_y.values, dtype=torch.float32)"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXoyKYs7UVp-"
      },
      "source": [
        "dl_train_weight_x = torch.utils.data.DataLoader(tensor_x, batch_size=BATCH_SIZE)\n",
        "dl_train_weight_y = torch.utils.data.DataLoader(tensor_y, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0geYXVhRnny"
      },
      "source": [
        "Agora, vamos treinar a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVitDKWQg3pm",
        "outputId": "48cee7a0-d016-488e-fb61-4afe67c74647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Guarda a loss ao longo das épocas para posteriormente plotar seu gráfico\n",
        "loss_over_epochs = []\n",
        "\n",
        "#Treinando o modelo\n",
        "for epoch in range(EPOCHS):\n",
        "  #Carregando os iteradores de batch\n",
        "  iter_x = iter(dl_train_weight_x)\n",
        "  iter_y = iter(dl_train_weight_y)\n",
        "\n",
        "  for i in range(0, len(train_weight_x), BATCH_SIZE):\n",
        "\n",
        "    #Alocando batch do iterador\n",
        "    batch_X = iter_x.next()\n",
        "    batch_y = iter_y.next()\n",
        "\n",
        "    #Zerando a loss function para não acumular\n",
        "    cardio_model.zero_grad()\n",
        "\n",
        "    #Forward Prop\n",
        "    outputs = cardio_model(batch_X)\n",
        "\n",
        "    #Calculando a loss\n",
        "    loss = loss_function(outputs, batch_y)\n",
        "    #Backward Prop\n",
        "    loss.backward()\n",
        "\n",
        "    #Atualizando os pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % print_results == 0:\n",
        "      #Printando perda e informações\n",
        "      loss_over_epochs.append(loss.item())\n",
        "      print(\"Train Epoch: \", epoch, \"   LOSS: \", loss.item())"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch:  0    LOSS:  0.7040456533432007\n",
            "Train Epoch:  1    LOSS:  0.6891351938247681\n",
            "Train Epoch:  2    LOSS:  0.6607435941696167\n",
            "Train Epoch:  3    LOSS:  0.6476795673370361\n",
            "Train Epoch:  4    LOSS:  0.6382497549057007\n",
            "Train Epoch:  5    LOSS:  0.6297762393951416\n",
            "Train Epoch:  6    LOSS:  0.6236057877540588\n",
            "Train Epoch:  7    LOSS:  0.6200417876243591\n",
            "Train Epoch:  8    LOSS:  0.6181237101554871\n",
            "Train Epoch:  9    LOSS:  0.6170479655265808\n",
            "Train Epoch:  10    LOSS:  0.616327166557312\n",
            "Train Epoch:  11    LOSS:  0.6158224940299988\n",
            "Train Epoch:  12    LOSS:  0.6154344081878662\n",
            "Train Epoch:  13    LOSS:  0.6151894927024841\n",
            "Train Epoch:  14    LOSS:  0.6149450540542603\n",
            "Train Epoch:  15    LOSS:  0.6147929430007935\n",
            "Train Epoch:  16    LOSS:  0.6145835518836975\n",
            "Train Epoch:  17    LOSS:  0.6143770217895508\n",
            "Train Epoch:  18    LOSS:  0.6141066551208496\n",
            "Train Epoch:  19    LOSS:  0.613876223564148\n",
            "Train Epoch:  20    LOSS:  0.6136170625686646\n",
            "Train Epoch:  21    LOSS:  0.6134771108627319\n",
            "Train Epoch:  22    LOSS:  0.6132458448410034\n",
            "Train Epoch:  23    LOSS:  0.612980306148529\n",
            "Train Epoch:  24    LOSS:  0.6127623915672302\n",
            "Train Epoch:  25    LOSS:  0.6125504374504089\n",
            "Train Epoch:  26    LOSS:  0.612339437007904\n",
            "Train Epoch:  27    LOSS:  0.6121021509170532\n",
            "Train Epoch:  28    LOSS:  0.6118670701980591\n",
            "Train Epoch:  29    LOSS:  0.6116504073143005\n",
            "Train Epoch:  30    LOSS:  0.6114474534988403\n",
            "Train Epoch:  31    LOSS:  0.6111503839492798\n",
            "Train Epoch:  32    LOSS:  0.6109052896499634\n",
            "Train Epoch:  33    LOSS:  0.6106684803962708\n",
            "Train Epoch:  34    LOSS:  0.6104395389556885\n",
            "Train Epoch:  35    LOSS:  0.6101763844490051\n",
            "Train Epoch:  36    LOSS:  0.6099797487258911\n",
            "Train Epoch:  37    LOSS:  0.6096645593643188\n",
            "Train Epoch:  38    LOSS:  0.6094318628311157\n",
            "Train Epoch:  39    LOSS:  0.6091923117637634\n",
            "Train Epoch:  40    LOSS:  0.6089403629302979\n",
            "Train Epoch:  41    LOSS:  0.6086234450340271\n",
            "Train Epoch:  42    LOSS:  0.6083090305328369\n",
            "Train Epoch:  43    LOSS:  0.6079733371734619\n",
            "Train Epoch:  44    LOSS:  0.6075958013534546\n",
            "Train Epoch:  45    LOSS:  0.6072491407394409\n",
            "Train Epoch:  46    LOSS:  0.6069027185440063\n",
            "Train Epoch:  47    LOSS:  0.6064999103546143\n",
            "Train Epoch:  48    LOSS:  0.6060821413993835\n",
            "Train Epoch:  49    LOSS:  0.6056773662567139\n",
            "Train Epoch:  50    LOSS:  0.6052424311637878\n",
            "Train Epoch:  51    LOSS:  0.6047876477241516\n",
            "Train Epoch:  52    LOSS:  0.6043142676353455\n",
            "Train Epoch:  53    LOSS:  0.603827953338623\n",
            "Train Epoch:  54    LOSS:  0.6033397316932678\n",
            "Train Epoch:  55    LOSS:  0.6027535796165466\n",
            "Train Epoch:  56    LOSS:  0.6021777391433716\n",
            "Train Epoch:  57    LOSS:  0.6014912724494934\n",
            "Train Epoch:  58    LOSS:  0.6008970141410828\n",
            "Train Epoch:  59    LOSS:  0.6003244519233704\n",
            "Train Epoch:  60    LOSS:  0.5997227430343628\n",
            "Train Epoch:  61    LOSS:  0.5990613102912903\n",
            "Train Epoch:  62    LOSS:  0.598431408405304\n",
            "Train Epoch:  63    LOSS:  0.5977150201797485\n",
            "Train Epoch:  64    LOSS:  0.5968648791313171\n",
            "Train Epoch:  65    LOSS:  0.5960639715194702\n",
            "Train Epoch:  66    LOSS:  0.5952091813087463\n",
            "Train Epoch:  67    LOSS:  0.5943320989608765\n",
            "Train Epoch:  68    LOSS:  0.5933548212051392\n",
            "Train Epoch:  69    LOSS:  0.5923454761505127\n",
            "Train Epoch:  70    LOSS:  0.5912178754806519\n",
            "Train Epoch:  71    LOSS:  0.5902411937713623\n",
            "Train Epoch:  72    LOSS:  0.5892151594161987\n",
            "Train Epoch:  73    LOSS:  0.5882344245910645\n",
            "Train Epoch:  74    LOSS:  0.5870782732963562\n",
            "Train Epoch:  75    LOSS:  0.5859295725822449\n",
            "Train Epoch:  76    LOSS:  0.5848915576934814\n",
            "Train Epoch:  77    LOSS:  0.5837656259536743\n",
            "Train Epoch:  78    LOSS:  0.582729160785675\n",
            "Train Epoch:  79    LOSS:  0.5816157460212708\n",
            "Train Epoch:  80    LOSS:  0.5806301832199097\n",
            "Train Epoch:  81    LOSS:  0.579412579536438\n",
            "Train Epoch:  82    LOSS:  0.5783151984214783\n",
            "Train Epoch:  83    LOSS:  0.5772303342819214\n",
            "Train Epoch:  84    LOSS:  0.576026201248169\n",
            "Train Epoch:  85    LOSS:  0.5748318433761597\n",
            "Train Epoch:  86    LOSS:  0.5737116932868958\n",
            "Train Epoch:  87    LOSS:  0.5724965333938599\n",
            "Train Epoch:  88    LOSS:  0.5713521838188171\n",
            "Train Epoch:  89    LOSS:  0.5703067779541016\n",
            "Train Epoch:  90    LOSS:  0.5692567229270935\n",
            "Train Epoch:  91    LOSS:  0.5682506561279297\n",
            "Train Epoch:  92    LOSS:  0.567212700843811\n",
            "Train Epoch:  93    LOSS:  0.5660311579704285\n",
            "Train Epoch:  94    LOSS:  0.5649805068969727\n",
            "Train Epoch:  95    LOSS:  0.5639286041259766\n",
            "Train Epoch:  96    LOSS:  0.5628455877304077\n",
            "Train Epoch:  97    LOSS:  0.5618114471435547\n",
            "Train Epoch:  98    LOSS:  0.5608720183372498\n",
            "Train Epoch:  99    LOSS:  0.5599111914634705\n",
            "Train Epoch:  100    LOSS:  0.559036374092102\n",
            "Train Epoch:  101    LOSS:  0.558125913143158\n",
            "Train Epoch:  102    LOSS:  0.5571557283401489\n",
            "Train Epoch:  103    LOSS:  0.5563529133796692\n",
            "Train Epoch:  104    LOSS:  0.5555208921432495\n",
            "Train Epoch:  105    LOSS:  0.5546993613243103\n",
            "Train Epoch:  106    LOSS:  0.5539149045944214\n",
            "Train Epoch:  107    LOSS:  0.553073525428772\n",
            "Train Epoch:  108    LOSS:  0.5522228479385376\n",
            "Train Epoch:  109    LOSS:  0.5514469146728516\n",
            "Train Epoch:  110    LOSS:  0.5507040023803711\n",
            "Train Epoch:  111    LOSS:  0.549877405166626\n",
            "Train Epoch:  112    LOSS:  0.5490142107009888\n",
            "Train Epoch:  113    LOSS:  0.548220157623291\n",
            "Train Epoch:  114    LOSS:  0.5474562048912048\n",
            "Train Epoch:  115    LOSS:  0.5467085242271423\n",
            "Train Epoch:  116    LOSS:  0.5460547208786011\n",
            "Train Epoch:  117    LOSS:  0.5453068017959595\n",
            "Train Epoch:  118    LOSS:  0.5445770621299744\n",
            "Train Epoch:  119    LOSS:  0.5440032482147217\n",
            "Train Epoch:  120    LOSS:  0.5434463620185852\n",
            "Train Epoch:  121    LOSS:  0.5427238345146179\n",
            "Train Epoch:  122    LOSS:  0.542254626750946\n",
            "Train Epoch:  123    LOSS:  0.5417195558547974\n",
            "Train Epoch:  124    LOSS:  0.5413222312927246\n",
            "Train Epoch:  125    LOSS:  0.5408098697662354\n",
            "Train Epoch:  126    LOSS:  0.5403609871864319\n",
            "Train Epoch:  127    LOSS:  0.5398957133293152\n",
            "Train Epoch:  128    LOSS:  0.5394411087036133\n",
            "Train Epoch:  129    LOSS:  0.5390245914459229\n",
            "Train Epoch:  130    LOSS:  0.5386167168617249\n",
            "Train Epoch:  131    LOSS:  0.538323700428009\n",
            "Train Epoch:  132    LOSS:  0.5379060506820679\n",
            "Train Epoch:  133    LOSS:  0.5376226305961609\n",
            "Train Epoch:  134    LOSS:  0.5372726321220398\n",
            "Train Epoch:  135    LOSS:  0.5369455814361572\n",
            "Train Epoch:  136    LOSS:  0.5366497039794922\n",
            "Train Epoch:  137    LOSS:  0.5363993048667908\n",
            "Train Epoch:  138    LOSS:  0.5362460017204285\n",
            "Train Epoch:  139    LOSS:  0.5359784364700317\n",
            "Train Epoch:  140    LOSS:  0.5357696413993835\n",
            "Train Epoch:  141    LOSS:  0.5355307459831238\n",
            "Train Epoch:  142    LOSS:  0.5353318452835083\n",
            "Train Epoch:  143    LOSS:  0.5350667834281921\n",
            "Train Epoch:  144    LOSS:  0.5348650217056274\n",
            "Train Epoch:  145    LOSS:  0.534707248210907\n",
            "Train Epoch:  146    LOSS:  0.5345398187637329\n",
            "Train Epoch:  147    LOSS:  0.5343518257141113\n",
            "Train Epoch:  148    LOSS:  0.5342223644256592\n",
            "Train Epoch:  149    LOSS:  0.5340760350227356\n",
            "Train Epoch:  150    LOSS:  0.5339184999465942\n",
            "Train Epoch:  151    LOSS:  0.5337125658988953\n",
            "Train Epoch:  152    LOSS:  0.5335821509361267\n",
            "Train Epoch:  153    LOSS:  0.5334656238555908\n",
            "Train Epoch:  154    LOSS:  0.5333646535873413\n",
            "Train Epoch:  155    LOSS:  0.5332289338111877\n",
            "Train Epoch:  156    LOSS:  0.5332223773002625\n",
            "Train Epoch:  157    LOSS:  0.533085286617279\n",
            "Train Epoch:  158    LOSS:  0.5328404307365417\n",
            "Train Epoch:  159    LOSS:  0.5327031016349792\n",
            "Train Epoch:  160    LOSS:  0.5326637029647827\n",
            "Train Epoch:  161    LOSS:  0.5324022173881531\n",
            "Train Epoch:  162    LOSS:  0.5324578285217285\n",
            "Train Epoch:  163    LOSS:  0.5323262214660645\n",
            "Train Epoch:  164    LOSS:  0.5322481989860535\n",
            "Train Epoch:  165    LOSS:  0.5323477387428284\n",
            "Train Epoch:  166    LOSS:  0.5326845049858093\n",
            "Train Epoch:  167    LOSS:  0.5344257354736328\n",
            "Train Epoch:  168    LOSS:  0.5349419713020325\n",
            "Train Epoch:  169    LOSS:  0.5347556471824646\n",
            "Train Epoch:  170    LOSS:  0.5347653031349182\n",
            "Train Epoch:  171    LOSS:  0.5343967080116272\n",
            "Train Epoch:  172    LOSS:  0.5344547629356384\n",
            "Train Epoch:  173    LOSS:  0.5348213315010071\n",
            "Train Epoch:  174    LOSS:  0.5345491766929626\n",
            "Train Epoch:  175    LOSS:  0.534372091293335\n",
            "Train Epoch:  176    LOSS:  0.5340645909309387\n",
            "Train Epoch:  177    LOSS:  0.5339263677597046\n",
            "Train Epoch:  178    LOSS:  0.5339493155479431\n",
            "Train Epoch:  179    LOSS:  0.5334196090698242\n",
            "Train Epoch:  180    LOSS:  0.5335042476654053\n",
            "Train Epoch:  181    LOSS:  0.5330362915992737\n",
            "Train Epoch:  182    LOSS:  0.5329426527023315\n",
            "Train Epoch:  183    LOSS:  0.5336810946464539\n",
            "Train Epoch:  184    LOSS:  0.5334575176239014\n",
            "Train Epoch:  185    LOSS:  0.5332427620887756\n",
            "Train Epoch:  186    LOSS:  0.5330127477645874\n",
            "Train Epoch:  187    LOSS:  0.5328853130340576\n",
            "Train Epoch:  188    LOSS:  0.5327908992767334\n",
            "Train Epoch:  189    LOSS:  0.53312748670578\n",
            "Train Epoch:  190    LOSS:  0.5330483913421631\n",
            "Train Epoch:  191    LOSS:  0.5327133536338806\n",
            "Train Epoch:  192    LOSS:  0.5324094295501709\n",
            "Train Epoch:  193    LOSS:  0.5319834351539612\n",
            "Train Epoch:  194    LOSS:  0.5317860841751099\n",
            "Train Epoch:  195    LOSS:  0.5312056541442871\n",
            "Train Epoch:  196    LOSS:  0.5311456918716431\n",
            "Train Epoch:  197    LOSS:  0.5309567451477051\n",
            "Train Epoch:  198    LOSS:  0.5310024619102478\n",
            "Train Epoch:  199    LOSS:  0.531134843826294\n",
            "Train Epoch:  200    LOSS:  0.5307695865631104\n",
            "Train Epoch:  201    LOSS:  0.5304672718048096\n",
            "Train Epoch:  202    LOSS:  0.5305894017219543\n",
            "Train Epoch:  203    LOSS:  0.5305180549621582\n",
            "Train Epoch:  204    LOSS:  0.5301965475082397\n",
            "Train Epoch:  205    LOSS:  0.5301976799964905\n",
            "Train Epoch:  206    LOSS:  0.5299384593963623\n",
            "Train Epoch:  207    LOSS:  0.5298610329627991\n",
            "Train Epoch:  208    LOSS:  0.5296609997749329\n",
            "Train Epoch:  209    LOSS:  0.5296518206596375\n",
            "Train Epoch:  210    LOSS:  0.5296027064323425\n",
            "Train Epoch:  211    LOSS:  0.5295560956001282\n",
            "Train Epoch:  212    LOSS:  0.5294692516326904\n",
            "Train Epoch:  213    LOSS:  0.5295313596725464\n",
            "Train Epoch:  214    LOSS:  0.5292673707008362\n",
            "Train Epoch:  215    LOSS:  0.5292283892631531\n",
            "Train Epoch:  216    LOSS:  0.529258131980896\n",
            "Train Epoch:  217    LOSS:  0.5292949676513672\n",
            "Train Epoch:  218    LOSS:  0.5289832353591919\n",
            "Train Epoch:  219    LOSS:  0.5290659666061401\n",
            "Train Epoch:  220    LOSS:  0.528995931148529\n",
            "Train Epoch:  221    LOSS:  0.5288103222846985\n",
            "Train Epoch:  222    LOSS:  0.5291638970375061\n",
            "Train Epoch:  223    LOSS:  0.5288084745407104\n",
            "Train Epoch:  224    LOSS:  0.5287377834320068\n",
            "Train Epoch:  225    LOSS:  0.5285701751708984\n",
            "Train Epoch:  226    LOSS:  0.5287501811981201\n",
            "Train Epoch:  227    LOSS:  0.5285788774490356\n",
            "Train Epoch:  228    LOSS:  0.528496503829956\n",
            "Train Epoch:  229    LOSS:  0.5285847783088684\n",
            "Train Epoch:  230    LOSS:  0.5287312865257263\n",
            "Train Epoch:  231    LOSS:  0.5282976627349854\n",
            "Train Epoch:  232    LOSS:  0.5284882187843323\n",
            "Train Epoch:  233    LOSS:  0.5284053087234497\n",
            "Train Epoch:  234    LOSS:  0.5284992456436157\n",
            "Train Epoch:  235    LOSS:  0.5284998416900635\n",
            "Train Epoch:  236    LOSS:  0.528397798538208\n",
            "Train Epoch:  237    LOSS:  0.5283267498016357\n",
            "Train Epoch:  238    LOSS:  0.5293107032775879\n",
            "Train Epoch:  239    LOSS:  0.5283087491989136\n",
            "Train Epoch:  240    LOSS:  0.5288073420524597\n",
            "Train Epoch:  241    LOSS:  0.529211163520813\n",
            "Train Epoch:  242    LOSS:  0.5279841423034668\n",
            "Train Epoch:  243    LOSS:  0.5286581516265869\n",
            "Train Epoch:  244    LOSS:  0.5291276574134827\n",
            "Train Epoch:  245    LOSS:  0.5291396379470825\n",
            "Train Epoch:  246    LOSS:  0.5287384390830994\n",
            "Train Epoch:  247    LOSS:  0.5286747813224792\n",
            "Train Epoch:  248    LOSS:  0.5287337303161621\n",
            "Train Epoch:  249    LOSS:  0.5287560224533081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BzmCkK1DOGH"
      },
      "source": [
        "##**Abaixo, temos o gŕafico da Loss ao longo do treinamento.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReVLbbD2Bb1w",
        "outputId": "f050117e-d5bf-4b0b-ea90-5b69320dd213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#Plotando a Loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.grid(True, linestyle='-', which='major', color='lightgrey',alpha=0.5)\n",
        "plt.plot(loss_over_epochs, color='g', linewidth=1.5)\n",
        "\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJv5Kq12EODZ"
      },
      "source": [
        "##**Por fim, vamos avaliar a acurácia do nosso modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjJvbFdSGtY6"
      },
      "source": [
        "tensor_test_x = torch.tensor(test_weight_x.values, dtype=torch.float32)\n",
        "tensor_test_y = torch.tensor(test_weight_y.values, dtype=torch.float32)"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uHKR4iVG1wo"
      },
      "source": [
        "dl_test_weight_x = torch.utils.data.DataLoader(tensor_test_x, batch_size=1)\n",
        "dl_test_weight_y = torch.utils.data.DataLoader(tensor_test_y, batch_size=1)"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe0uo05AETn-",
        "outputId": "8c083278-9803-4300-c257-321d9ad145d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "true_positive = 0\n",
        "true_negative = 0\n",
        "false_positive = 0\n",
        "false_negative = 0\n",
        "\n",
        "#Carregando os iteradores de batch\n",
        "iter_x = iter(dl_test_weight_x)\n",
        "iter_y = iter(dl_test_weight_y)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in tqdm(range(len(test_weight_x))):\n",
        "\n",
        "    #Alocando batch do iterador\n",
        "    batch_X = iter_x.next()\n",
        "    batch_y = iter_y.next()\n",
        "\n",
        "    real_class = torch.argmax(batch_y)\n",
        "    net_out = cardio_model(batch_X)\n",
        "    \n",
        "    predicted_class = torch.argmax(net_out)\n",
        "\n",
        "    #print(\"NET OUT: \", net_out)\n",
        "    #print(\"REAL CLASS: \", real_class)\n",
        "\n",
        "    if(predicted_class == real_class):\n",
        "      correct += 1\n",
        "      #True Positive\n",
        "      if(predicted_class.item() == 1):\n",
        "        true_positive += 1\n",
        "      #True Negative\n",
        "      if(predicted_class.item() == 0):\n",
        "        true_negative += 1\n",
        "\n",
        "    else:\n",
        "      #False Positive \n",
        "      if(predicted_class.item() == 1):\n",
        "        false_positive += 1\n",
        "      #False Negative\n",
        "      elif(predicted_class.item() == 0):\n",
        "        false_negative += 1\n",
        "\n",
        "      \n",
        "    total += 1"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9998 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "100%|██████████| 9998/9998 [00:01<00:00, 6910.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwscONUyGkgg",
        "outputId": "1652a70c-c69f-4ff0-d829-8c3b02c98aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "#Printando a acurácia e a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "print(\"Accuracy: \", correct/total)\n",
        "print(\"\") \n",
        "\n",
        "confusion_matrix = [[true_positive, false_positive], [true_negative, false_negative]]\n",
        "\n",
        "sb.heatmap(confusion_matrix, vmin=1100, vmax=4000, annot=True, cmap=\"PiYG\")\n",
        "plt.xlabel(\"True/False\")\n",
        "plt.ylabel(\"Positive/Negative\")"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7224444888977796\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Positive/Negative')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7hu5-6dRmJQ"
      },
      "source": [
        "##Com isso, é possível ver que obtemos uma acurácia de aproximadamente 72% no nosso classificador. Analisando as discussões sobre esse dataset no kaggle, ninguém conseguiu ainda uma acurácia maior que essa.\n",
        "\n",
        "##Além disso, a autora do dataset ainda não forneceu a fonte deles, ou seja, não sabemos de onde os dados foram retirados.\n",
        "\n",
        "##Desse modo, essa baixa acurácia pode se dar por vários fatores. Existe a possibilidade de ninguém ter achado uma combinação de features, uma arquitetura ou modelo que maximizem os resultados. Como também é possível que os dados estejam viesados. \n",
        "\n",
        "##De qualquer forma, foi um ótimo exercício para praticar!"
      ]
    }
  ]
}